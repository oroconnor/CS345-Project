{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# runs the util notebook so that those functions are available\n",
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split data into test train split\n",
    "* Do a baseline default settings SVM model with linear one against the rest\n",
    "* Iterating through runs of SVM with different hyperparameters to find the best hyperparameters, using GridSearch. \n",
    "* Baseline with linear SVM, and *then explore options for nonlinear SVM. \n",
    "* Select the best model and justify\n",
    "* Test accuracy of best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, features = load_standardized_beans()\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test =  split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9265515975027543\n"
     ]
    }
   ],
   "source": [
    "# Doing a baseline SVM, with the default parameters. Default C is 1.0\n",
    "classifier = svm.SVC(kernel=\"linear\")\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_valid)\n",
    "print('accuracy: ', np.mean(y_valid == y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9263829521994449"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But let's do cross validation, and with Stratified K folds, to makes sure we have a good sense of the baseline. \n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, cross_val_score\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "accuracy = cross_val_score(classifier, X, y, cv=cv, \n",
    "                           scoring='accuracy')\n",
    "np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit Learn's documentation says that the One Versus One option for the decision_function_shape argument is deprecated, and that One Versus Rest is both recommended and the default. Doesn't seem to change the results much, so moving forward we will leave it with the default that the package recommends, the One Versus Rest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9263097466461845"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = svm.SVC(kernel=\"linear\", decision_function_shape='ovo')\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "accuracy = cross_val_score(classifier, X, y, cv=cv, \n",
    "                           scoring='accuracy')\n",
    "np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to verify our assumption, before we proceed forward, that the standardized data provides a benifit over the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying SVM classification with the non-standardized data\n",
    "\n",
    "X, y, features = load_beans()\n",
    "\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test =  split(X,y)\n",
    "\n",
    "classifier = svm.SVC(kernel=\"linear\")\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_valid)\n",
    "print('accuracy: ', np.mean(y_valid == y_pred))\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "accuracy = cross_val_score(classifier, X, y, cv=cv, \n",
    "                           scoring='accuracy')\n",
    "np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes. It looks like the standardized data provides some accuracy benefit over the raw data. Maybe the biggest improvement is with computation time. Regardless, we will leave the raw data behind now, and only work with the standardized data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have established a baseline model accuracy of **92.6%** using a linear SVM model with scikit learn's defaults and a standardized dataset, we will proceed to tuning our hyperparameters and seeing if we can find a better model for predicting the dry bean varieties. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
